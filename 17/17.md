# Level 17 


**[cookies.jpg](/17/cookies.jpg)** is given. If you look closely at the left bottom you can see it has a the same smaller image as [level4](/4/chainsaw.jpg).


The title of the HTML is `eat?` so it definitely has something to do with cookies.

Checking the cookie on the web page show this.

```html
you should have followed busynothing...
```

So I followed busynothing until there weren't anymore busynothings.


```python
import requests 

busynothing=12345
while True:
    res=requests.get(f"http://www.pythonchallenge.com/pc/def/linkedlist.php?busynothing={busynothing}")
    busynothing=res.text.split(" ")[-1]
    print(res.text)
    if "busynothing is" not in res.text:
        break
```

It spat out a whole lot of busynothings but nothing useful was there.

```
and the next busynothing is 96070
and the next busynothing is 83051
that's it.
```

I thought of checking the cookie value because the image given is a cookie. 

```python
import requests 

busynothing=12345
res=requests.get(f"http://www.pythonchallenge.com/pc/def/linkedlist.php?busynothing={busynothing}")
print(res.cookies) # <RequestsCookieJar[<Cookie info=B for .pythonchallenge.com/>]>
```


Huh a cookie value was found. Maybe I should try gathering all the cookie values. 

```python
import requests 

busynothing=12345
gathering=[]

while True:
    res=requests.get(f"http://www.pythonchallenge.com/pc/def/linkedlist.php?busynothing={busynothing}")
    busynothing=res.text.split(" ")[-1]
    cookies=res.cookies
    print(cookies)
    gathering.append(cookies.get('info'))
    if "busynothing is" not in res.text:
        break

print(gathering)

# ['B', 'Z', 'h', '9', '1', 'A', 'Y', '%26', 'S', 'Y', '%94', '%3A', '%E2', 'I', '%00', '%00', '%21', '%19', '%80', 'P', '%81', '%11', '%00', '%AF', 'g', '%9E', '%A0', '%20', '%00', 'h', 'E', '%3D', 'M', '%B5', '%23', '%D0', '%D4', '%D1', '%E2', '%8D', '%06', '%A9', '%FA', '%26', 'S', '%D4', '%D3', '%21', '%A1', '%EA', 'i', '7', 'h', '%9B', '%9A', '%2B', '%BF', '%60', '%22', '%C5', 'W', 'X', '%E1', '%AD', 'L', '%80', '%E8', 'V', '%3C', '%C6', '%A8', '%DB', 'H', '%26', '3', '2', '%18', '%A8', 'x', '%01', '%08', '%21', '%8D', 'S', '%0B', '%C8', '%AF', '%96', 'K', 'O', '%CA', '2', '%B0', '%F1', '%BD', '%1D', 'u', '%A0', '%86', '%05', '%92', 's', '%B0', '%92', '%C4', 'B', 'c', '%F1', 'w', '%24', 'S', '%85', '%09', '%09', 'C', '%AE', '%24', '%90']

print("".join(gathering))

# BZh91AY%26SY%94%3A%E2I%00%00%21%19%80P%81%11%00%AFg%9E%A0%20%00hE%3DM%B5%23%D0%D4%D1%E2%8D%06%A9%FA%26S%D4%D3%21%A1%EAi7h%9B%9A%2B%BF%60%22%C5WX%E1%ADL%80%E8V%3C%C6%A8%DBH%2632%18%A8x%01%08%21%8DS%0B%C8%AF%96KO%CA2%B0%F1%BD%1Du%A0%86%05%92s%B0%92%C4Bc%F1w%24S%85%09%09C%AE%24%90
```


Joining the cookie values into a string gives me the string below. It's a bzip compressed compressed data.


```
BZh91AY%26SY%94%3A%E2I%00%00%21%19%80P%81%11%00%AFg%9E%A0%20%00hE%3DM%B5%23%D0%D4%D1%E2%8D%06%A9%FA%26S%D4%D3%21%A1%EAi7h%9B%9A%2B%BF%60%22%C5WX%E1%ADL%80%E8V%3C%C6%A8%DBH%2632%18%A8x%01%08%21%8DS%0B%C8%AF%96KO%CA2%B0%F1%BD%1Du%A0%86%05%92s%B0%92%C4Bc%F1w%24S%85%09%09C%AE%24%90
```


```python
import bz2 

deflated=bz2.decompress(b"BZh91AY%26SY%94%3A%E2I%00%00%21%19%80P%81%11%00%AFg%9E%A0%20%00hE%3DM%B5%23%D0%D4%D1%E2%8D%06%A9%FA%26S%D4%D3%21%A1%EAi7h%9B%9A%2B%BF%60%22%C5WX%E1%ADL%80%E8V%3C%C6%A8%DBH%2632%18%A8x%01%08%21%8DS%0B%C8%AF%96KO%CA2%B0%F1%BD%1Du%A0%86%05%92s%B0%92%C4Bc%F1w%24S%85%09%09C%AE%24%90")
print(deflated)
```


I tried decompressing the bzip compressed file with the code above but got an `OSError: Invalid data stream`. The bzip compressed was **[URL-encoded](https://en.wikipedia.org/wiki/Percent-encoding)** (It has a lot of %26 and strings that start with %) that's why it spat out an error.


The requests modules provides `requests.utils.unquote` to URL-decode strings but the problem with `requests.utils.unquote` is that it can't decode some URL-encoded characters such as `%27`. A lot of the URL-encoded characters weren't properly URL-decoded when using `requests.utils.unquote`. 


```python
import requests

deflated=requests.utils.unquote(b"BZh91AY%26SY%94%3A%E2I%00%00%21%19%80P%81%11%00%AFg%9E%A0%20%00hE%3DM%B5%23%D0%D4%D1E2%8D%06%A9%FA%26S%D4%D3%21%A1%EAi7h%9B%9A%2B%BF%60%22%C5WX%E1%ADL%80%E8V%3C%C6%A8%DBH%2632%18%A8x%01%08%21%8DS%0B%C8%AF%96KO%CA2%B0%F1%BD%1Du%A0%86%05%92s%B0%92%C4Bc%F1w%24S%85%09%09C%AE%24%90")

print(deflated) # 'BZh91AY&SY�:�I\x00\x00!\x19�P�\x11\x00�g�� \x00hE=M�#����\x06��&S��!��i7h��+�`"�WX�L��V<ƨ�H&32\x18�x\x01\x08!�S\x0bȯ�KO�2��\x1du��\x05�s���Bc�w$S�\t\tC�$�

```

BTW `requests.utils.unquote` is a re-export or a thin-wrapper around **[urllib.parse.unquote](https://docs.python.org/3/library/urllib.parse.html#urllib.parse.unquote)** so it seems like a better idea to use **urllib.parse.unquote**. 


`requests.utils.unquote` doesn't have a document so I couldn't link it.


Unlike the `requests` module **[urllib](https://docs.python.org/3/library/urllib.html)** is a built-in module.


Since the type of our bzip compressed data is `bytes` it's actually better to use **[urllib.parse.unquote_to_bytes](https://docs.python.org/3/library/urllib.parse.html#urllib.parse.unquote_to_bytes)** because it returns `bytes`. Using `urllib.parse.unquote_to_bytes` makes it easier to decompress the bzip compressed data. 


```python
import urllib 

deflated=urllib.parse.unquotes_to_bytes(b"BZh91AY%26SY%94%3A%E2I%00%00%21%19%80P%81%11%00%AFg%9E%A0%20%00hE%3DM%B5%23%D0%D4%D1%E2%8D%06%A9%FA%26S%D4%D3%21%A1%EAi7h%9B%9A%2B%BF%60%22%C5WX%E1%ADL%80%E8V%3C%C6%A8%DBH%2632%18%A8x%01%08%21%8DS%0B%C8%AF%96KO%CA2%B0%F1%BD%1Du%A0%86%05%92s%B0%92%C4Bc%F1w%24S%85%09%09C%AE%24%90")

print(deflated) # b'BZh91AY&SY\x94:\xe2I\x00\x00!\x19\x80P\x81\x11\x00\xafg\x9e\xa0 \x00hE=M\xb5#\xd0\xd4\xd1\xe2\x8d\x06\xa9\xfa&S\xd4\xd3!\xa1\xeai7h\x9b\x9a+\xbf`"\xc5WX\xe1\xadL\x80\xe8V<\xc6\xa8\xdbH&32\x18\xa8x\x01\x08!\x8dS\x0b\xc8\xaf\x96KO\xca2\xb0\xf1\xbd\x1du\xa0\x86\x05\x92s\xb0\x92\xc4Bc\xf1w$S\x85\t\tC\xae$\x90'
```


Finally a proper byte-string that's URL-decoded and bzip compressed data.


Decompressing it with `bz2` gives me this.


```python
import bz2 

print(bz2.decompress(b'BZh91AY&SY\x94:\xe2I\x00\x00!\x19\x80P\x81\x11\x00\xafg\x9e\xa0 \x00hE=M\xb5#\xd0\xd4\xd1\xe2\x8d\x06\xa9\xfa&S\xd4\xd3!\xa1\xeai7h\x9b\x9a+\xbf`"\xc5WX\xe1\xadL\x80\xe8V<\xc6\xa8\xdbH&32\x18\xa8x\x01\x08!\x8dS\x0b\xc8\xaf\x96KO\xca2\xb0\xf1\xbd\x1du\xa0\x86\x05\x92s\xb0\x92\xc4Bc\xf1w$S\x85\t\tC\xae$\x90'))

# b'is it the 26th already? call his father and inform him that "the flowers are on their way". he\'ll understand.'
```

I remember someone born on the `26th`. It was Mozart. Mozart has a dad, his name is **[Leopold](https://en.wikipedia.org/wiki/Leopold_Mozart)**. We also need to call him. I'll have to use the code from level13.


```python
import xmlrpc.client

class MyTransport(xmlrpc.client.Transport):
    accept_gzip_encoding = False 

conn = xmlrpc.client.ServerProxy("http://www.pythonchallenge.com/pc/phonebook.php", transport=MyTransport())

print(conn.system.listMethods()) # ['phone', 'system.listMethods', 'system.methodHelp', 'system.methodSignature', 'system.multicall', 'system.getCapabilities']

print(conn.phone("Leopold")) # 555-VIOLIN

```


**555-VIOLIN** is what I got after calling Leopold. I need to get rid of the `555` because that's BS. Changing the URL to **[violin](http://www.huge:file@pythonchallenge.com/pc/return/violin.html)** takes me to another web page.


It says `no! i mean yes! but ../stuff/violin.php.`. Changing the URL to http://www.huge:file@pythonchallenge.com/pc/stuff/violin.php takes you to level18. 


You can check out the full code [here](/17/17.py).


I think level17 was a combination of a lot of the previous levels. It leveraged Level4 (for the busynothings), level8 (decompressing bzip data), level13 (using xml-rpc). The slight twist was that you had to URL-decode the string using `urllib`.


I personally thought this level wasn't that hard compared to level14 and level16. I enjoyed level16 a lot.